{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment 3 -- Text Classification\n",
    "\n",
    "You are given training data in the form of product and review information for 1500 products.  Each is labeled as being in the category **Books** or  **Movies & TV** or **Music**\n",
    "\n",
    "There are two parts to the assignment:  delivering the classifier, and documenting the research that went into choosing the best model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Input Data\n",
    "\n",
    "There are two files, *products.txt* and *reviews.txt* which are in the same format as the data files in Assignment 2.\n",
    "The product category label appears in the **salesRank** attribute.   \n",
    "\n",
    "Notice that there is also an attribute **categories** in this data set.  ***You are not allowed to use the attribute*** *categories* ***for this assignment.***\n",
    "\n",
    "The file *reviews.txt* contains reviews for the products in *products.txt*.\n",
    "\n",
    "The code to build your model should assume that these files are present in the same directory as the workbook, that all the records in *products.txt* have one of the three categories above, and that every record in *reviews.txt* refers to a product  that appears in *products.txt*.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parts to the Assignment\n",
    "\n",
    "In the first part of the assignment you will put code to train your model and to preprocess test data. After that, you will answer some questions about experiments you conducted and decisions you made in building your \"best\" model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Model and its Evaluation\n",
    "\n",
    "These are the two functions that will allow evaluation of your model.\n",
    "\n",
    "The first reads training data, prepares the data (extracts fields from the files, builds the response variable, vectorizes the X, and possibly reduces the feature set), then trains the model on that data (using the fit method).  The model returned should be ready to predict X values.\n",
    "\n",
    "The second just does the preprocessing steps, producing an X and a y.\n",
    "\n",
    "To evaluate your model, I will first use build_model to train it -- the two files will be in the same format as the files you got as part of the assignment, but may contain different data records.   After training the model, I will call prepare_data using a different set of test data, then evaluate the model by callithe X matrix it produces.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns a model -- an object that at least implements a predict method.\n",
    "# The two parameters are names of files containing labeled training data\n",
    "# The model returned should already be trained on (fitted to) the data in those two files\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "def load_input(file_name):\n",
    "    raw_input = []\n",
    "    for line in open(file_name):\n",
    "        raw_input.append(eval('(' + line + ')'))\n",
    "    return raw_input\n",
    "\n",
    "def make_training(product_file_name, review_file_name):\n",
    "    products = {}\n",
    "    reviews = {}\n",
    "    txts = []\n",
    "    ys = []    \n",
    "    for raw_product in load_input(product_file_name):\n",
    "        products[raw_product['asin']] = list(raw_product['salesRank'].keys())[0]\n",
    "    \n",
    "    for raw_review in load_input(review_file_name):\n",
    "        txt = raw_review['summary'] + ' ' + raw_review['reviewText']\n",
    "        if(raw_review['asin'] in reviews.keys()):\n",
    "            reviews[raw_review['asin']].append(txt)\n",
    "        else:\n",
    "            reviews[raw_review['asin']] = [txt]\n",
    "            \n",
    "    for asin, list_texts in reviews.items():\n",
    "        for text in list_texts:\n",
    "            txts.append(text)\n",
    "            ys.append(products[asin])\n",
    "    return txts, ys\n",
    "\n",
    "def build_model(product_file_name=\"products.txt\", review_file_name=\"reviews.txt\"):\n",
    "    txts, y = make_training(product_file_name, review_file_name)\n",
    "    v = CountVectorizer() # TODO: change the parameters!\n",
    "    X = v.fit_transform(txts)\n",
    "    print(X.shape)\n",
    "    nb = MultinomialNB()\n",
    "    nb.fit(X,y)\n",
    "    # TODO: optimize the model, hyperparameters, cv\n",
    "    return nb\n",
    "\n",
    "# Returns an X matrix and y vector which are prepared using the same preprocessing\n",
    "# steps used to build and train the model returned by build_model above\n",
    "\n",
    "def prepare_data(product_file_name, review_file_name):\n",
    "    txts, y = make_training(product_file_name, review_file_name) \n",
    "    \n",
    "    #with or without training??\n",
    "    v = CountVectorizer() # TODO: change the parameters!\n",
    "    X = v.fit_transform(txts)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17757, 54770)\n"
     ]
    }
   ],
   "source": [
    "# remove me before submission!!\n",
    "nb = build_model(\"products.txt\", \"reviews.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------------------------\n",
    "### Documenting your Decisions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation and Analysis\n",
    "\n",
    "In answering these questions, please be sure to show your work, for example output of commands you used to gather data supporting your decisions.   For each of the cells below containing a question, please leave the question header and text in the notbook you subnmit.  Put you answer in markdown in the same cell, and add additional cells below the question/answer cell for supporting data (output, tables, graphics).  I will evaluate your notebook from beginning to end prior to evaluating the model or reading your analysis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------\n",
    "#### Model Quality\n",
    "\n",
    "What do you expect the accuracy of your model to be on a new set of product records it has not seen before?\n",
    "How many variables are in your model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------\n",
    "#### Input Fields\n",
    "\n",
    "What input fields from the product and review records did you include in training your model?\n",
    "How did you decide which fields to use and which to omit?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------\n",
    "#### Preprocessing\n",
    "\n",
    "What preprocessing steps did you use?  At minimum you must evaluate stemming, tokenizing, stop word removal.  How did you decide which steps improved the model and which did not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------\n",
    "#### Vectorization\n",
    "\n",
    "What technique did you use to turn the input features into a feature vector?  How did you make that choice?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------\n",
    "####  Feature Selection\n",
    "\n",
    "It is important to examine and understand the model features both to convince that the important features are plausible, and to consider removing the unimportant features.  What features did you use in the model, and how did you make that choice?  List some of the most important features.  Are you convinced that they are are accurate exemplars of the class, or might they be artifacts of the training set?  List some of the least important features -- do they suggest ways to cut down the model size without significantly affecting accuracy?  \n",
    "\n",
    "In class we looked at three ways of estimating the impact of a term on a model\n",
    "\n",
    "* Frequency-based selection\n",
    "* Mutual information\n",
    "* Feature log probabilities, i.e. $P(f_i | C)$\n",
    "\n",
    "How different are the three measures, i.e. do they all tend to rank the same variables as significant and insignificant?  Which did you use in your model, and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------\n",
    "#### Algorithm\n",
    "\n",
    "Which classification algorithm did you use;  what alternatives did you explore and how did you make the choice?  What hyperparameter optimization did you perform?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------\n",
    "#### Understanding Misclassifications\n",
    "\n",
    "Even though misclassifications are inevitable, it is important to understand *why* your algorithm makes errors, and whether it is making \"understandable\" errors.   Choose several examples of misclassification and informally explain why you believe the classifier made the wrong choice.  Is/was there anything you might be able to do in terms of feature engineering to fix some misclassifications?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
